# Legal RAG System - Há»‡ thá»‘ng TÆ° váº¥n PhÃ¡p luáº­t AI

> Há»‡ thá»‘ng RAG (Retrieval-Augmented Generation) chuyÃªn sÃ¢u cho tÆ° váº¥n phÃ¡p luáº­t Viá»‡t Nam vá»›i **Hybrid Search** (Vector + BM25) vÃ  **Deep Thinking Mode**.

## ğŸ¯ TÃ­nh nÄƒng chÃ­nh

- âœ… **Hybrid Search**: Káº¿t há»£p FAISS (vector) vÃ  BM25 (sparse) vá»›i tá»· lá»‡ 60:40
- ğŸ§  **Deep Thinking Mode**: TrÃ­ch xuáº¥t keywords â†’ Multi-query search â†’ Merge thÃ´ng minh
- ğŸ’¬ **Session Memory**: LÆ°u lá»‹ch sá»­ há»™i thoáº¡i vá»›i semantic search
- ğŸ“Š **Performance Monitoring**: Theo dÃµi timing tá»«ng bÆ°á»›c xá»­ lÃ½
- ğŸ”„ **Circuit Breaker**: Tá»± Ä‘á»™ng retry vÃ  fallback khi service lá»—i
- ğŸ‡»ğŸ‡³ **Vietnamese Optimized**: Tokenizer vÃ  embedding chuyÃªn biá»‡t cho tiáº¿ng Viá»‡t

---

## ğŸ“‹ YÃªu cáº§u há»‡ thá»‘ng

- **Java**: 17 hoáº·c cao hÆ¡n
- **Python**: 3.8+ (cho embedding service)
- **Maven**: 3.6+ (hoáº·c dÃ¹ng `mvnw` Ä‘i kÃ¨m)
- **Ollama**: ÄÃ£ cÃ i Ä‘áº·t vÃ  pull model `gpt-oss:120b-cloud`

## ğŸš€ CÃ i Ä‘áº·t

### BÆ°á»›c 1: Clone repository

```bash
git clone https://github.com/your-org/legal-rag-springboot.git
cd legal-rag-springboot
```

### BÆ°á»›c 2: CÃ i Ä‘áº·t Python dependencies

```bash
pip install -r requirements.txt
```

### BÆ°á»›c 3: Chuáº©n bá»‹ dá»¯ liá»‡u

Äáº·t cÃ¡c file dá»¯ liá»‡u vÃ o thÆ° má»¥c `data/`:

```
data/
â”œâ”€â”€ faiss.index           # FAISS vector index
â”œâ”€â”€ data_corpus.json      # Corpus vÄƒn báº£n phÃ¡p luáº­t
â”œâ”€â”€ metadata.jsonl        # Metadata chunks
â””â”€â”€ bm25_cache.gz         # BM25 cache (tá»± Ä‘á»™ng táº¡o láº§n Ä‘áº§u)
```

### BÆ°á»›c 4: CÃ i Ä‘áº·t vÃ  cháº¡y Ollama

```bash
# CÃ i Ä‘áº·t Ollama (náº¿u chÆ°a cÃ³)
curl -fsSL https://ollama.com/install.sh | sh

# Pull model
ollama pull gpt-oss:120b-cloud

# Kiá»ƒm tra model Ä‘Ã£ sáºµn sÃ ng
ollama list
```

### BÆ°á»›c 5: Build vÃ  cháº¡y á»©ng dá»¥ng

```bash
# Sá»­ dá»¥ng Maven wrapper
./mvnw clean install
./mvnw spring-boot:run

# Hoáº·c dÃ¹ng Maven Ä‘Ã£ cÃ i
mvn clean install
mvn spring-boot:run
```

**á»¨ng dá»¥ng sáº½ cháº¡y táº¡i**: `http://localhost:8080`

---

## ğŸ”§ Cáº¥u hÃ¬nh

### File `application.yml`

#### 1. **Ollama Configuration**

```yaml
spring:
  ai:
    ollama:
      base-url: http://localhost:11434  	# Ollama service URL
      chat:
        options:
          model: gpt-oss:120b-cloud      	# Model name
          temperature: 0.1               	# Äá»™ sÃ¡ng táº¡o (tháº¥p = deterministic)
          num-predict: 4096               	# Max output tokens
```

#### 2. **Python Embedding Service**

```yaml
legal-rag:
  embedding:
    dimension: 768                       	# Vector dimension
    auto-start: true                     	# Tá»± Ä‘á»™ng start Python service
    timeout-seconds: 60
    python-command: python               	# Hoáº·c python3
    python-script-path: scripts/embedding_service.py
```

#### 3. **RAG Configuration**

```yaml
legal-rag:
  rag:
    retrieval:
      top-k: 100                         # Sá»‘ docs láº¥y tá»« má»—i search
      rerank-top-k: 15                   # Sá»‘ docs sau rerank
      alpha: 0.6                         # Hybrid weight (0.6 = 60% vector)
  
    deep-thinking:
      enabled: true
      top-k-per-keyword: 30              # Docs má»—i keyword
      final-top-k: 8                     # Docs cuá»‘i cÃ¹ng
      max-keywords: 10                   # Max keywords extract
```

#### 4. **Dataset Paths**

```yaml
legal-rag:
  dataset:
    index: data/faiss.index
    metadata: data/metadata.jsonl
    corpus: data/data_corpus.json
    bm25-cache: data/bm25_cache.gz
```

---

## ğŸ“– Sá»­ dá»¥ng API

### 1. Health Check

```bash
curl http://localhost:8080/api/health
```

**Response**:

```json
{
  "status": "healthy",
  "timestamp": "2026-02-08T10:30:00Z",
  "service": "Legal RAG API",
  "features": {
    "deep_thinking": true
  },
  "active_sessions": 0
}
```

---

### 2. Query - Base RAG Mode (Nhanh)

```bash
curl -X POST http://localhost:8080/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Má»©c pháº¡t vi pháº¡m giao thÃ´ng khÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm lÃ  bao nhiÃªu?",
    "useDeepThinking": false,
    "sessionId": "user-123"
  }'
```

**Response**:

```json
{
  "question": "Má»©c pháº¡t vi pháº¡m giao thÃ´ng...",
  "answer": "Theo Nghá»‹ Ä‘á»‹nh 100/2019/NÄ-CP, má»©c pháº¡t tá»« 400.000Ä‘ Ä‘áº¿n 600.000Ä‘...",
  "context": [
    {
      "rank": 1,
      "score": 0.89,
      "chunkId": "chunk_123",
      "text": "Äiá»u 6. Pháº¡t tiá»n Ä‘á»‘i vá»›i ngÆ°á»i Ä‘iá»u khiá»ƒn xe mÃ´ tÃ´..."
    }
  ],
  "timing": {
    "totalTime": 2.5,
    "stepDurations": {
      "Dense Search": 0.3,
      "BM25 Search": 0.2,
      "Score Fusion": 0.1,
      "Reranking": 0.4,
      "LLM Generation": 1.5
    }
  },
  "sessionId": "user-123",
  "mode": "base_rag"
}
```

---

### 3. Query - Deep Thinking Mode (ChuyÃªn sÃ¢u)

```bash
curl -X POST http://localhost:8080/api/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "So sÃ¡nh hÃ¬nh pháº¡t giá»¯a trá»™m cáº¯p vÃ  cÆ°á»›p giáº­t tÃ i sáº£n?",
    "useDeepThinking": true,
    "sessionId": "user-123"
  }'
```

**Response**:

```json
{
  "question": "So sÃ¡nh hÃ¬nh pháº¡t...",
  "answer": "Vá» trá»™m cáº¯p tÃ i sáº£n:\n- Äiá»u 173 BLHS 2015...\n\nVá» cÆ°á»›p giáº­t:\n- Äiá»u 136 BLHS 2015...",
  "context": [...],
  "keywords": ["trá»™m cáº¯p", "cÆ°á»›p giáº­t", "hÃ¬nh pháº¡t", "tÃ i sáº£n"],
  "thinkingProcess": {
    "keywords": ["trá»™m cáº¯p", "cÆ°á»›p giáº­t", "hÃ¬nh pháº¡t"],
    "reasoning": "CÃ¢u há»i yÃªu cáº§u so sÃ¡nh 2 hÃ nh vi pháº¡m tá»™i...",
    "searches_performed": 3,
    "total_docs_found": 8
  },
  "timing": {...},
  "sessionId": "user-123",
  "mode": "deep_thinking"
}
```

---

### 4. Session History

```bash
curl http://localhost:8080/api/session/user-123/history
```

**Response**:

```json
{
  "sessionId": "user-123",
  "totalTurns": 5,
  "conversations": [
    {
      "timestamp": "2026-02-08T10:30:00Z",
      "question": "Má»©c pháº¡t khÃ´ng Ä‘á»™i mÅ© báº£o hiá»ƒm?",
      "answer": "Theo Nghá»‹ Ä‘á»‹nh 100/2019...",
      "metadata": {
        "mode": "base_rag",
        "timing": {...}
      }
    }
  ]
}
```

---

### 5. Delete Session

```bash
curl -X DELETE http://localhost:8080/api/session/user-123
```

---

### 6. Performance Statistics

```bash
curl http://localhost:8080/api/performance/stats
```

**Response**:

```json
{
  "totalQueries": 150,
  "avgTotalTime": 2.8,
  "medianTotalTime": 2.5,
  "stepStatistics": {
    "Dense Search": {"avg": 0.3, "median": 0.28, "min": 0.2, "max": 0.5},
    "BM25 Search": {"avg": 0.2, "median": 0.18, "min": 0.15, "max": 0.3},
    "LLM Generation": {"avg": 1.5, "median": 1.4, "min": 0.8, "max": 3.2}
  }
}
```

---

## ğŸ›ï¸ So sÃ¡nh 2 cháº¿ Ä‘á»™

| TÃ­nh nÄƒng                | Base RAG                              | Deep Thinking                    |
| -------------------------- | ------------------------------------- | -------------------------------- |
| **Tá»‘c Ä‘á»™**        | Nhanh                                 | Cháº­m hÆ¡n (5-8s)                |
| **Äá»™ chÃ­nh xÃ¡c** | Tá»‘t                                  | Ráº¥t tá»‘t                        |
| **Use case**         | CÃ¢u há»i Ä‘Æ¡n giáº£n, tra cá»©u nhanh | PhÃ¢n tÃ­ch phá»©c táº¡p, so sÃ¡nh |
| **Context**          | 15 docs                               | 8 docs (Ä‘Ã£ lá»c ká»¹)           |
| **Keywords**         | KhÃ´ng cÃ³                            | CÃ³ (LLM extract)                |
| **Multi-query**      | KhÃ´ng                                | CÃ³                              |

**Khi nÃ o dÃ¹ng Deep Thinking?**

- âœ… CÃ¢u há»i phá»©c táº¡p, nhiá»u khÃ­a cáº¡nh
- âœ… Cáº§n so sÃ¡nh, phÃ¢n tÃ­ch
- âœ… YÃªu cáº§u Ä‘á»™ chÃ­nh xÃ¡c cao

**Khi nÃ o dÃ¹ng Base RAG?**

- âœ… Tra cá»©u nhanh
- âœ… CÃ¢u há»i Ä‘Æ¡n giáº£n, rÃµ rÃ ng
- âœ… Cáº§n response time tháº¥p

---

## ğŸ“ Cáº¥u trÃºc Project

```
legal-rag-springboot/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ main/
â”‚       â”œâ”€â”€ java/
â”‚       â”‚   â””â”€â”€ com/
â”‚       â”‚       â””â”€â”€ legalrag/
â”‚       â”‚           â”œâ”€â”€ config/              # Spring configs
â”‚       â”‚           â”œâ”€â”€ controller/          # REST controllers
â”‚       â”‚           â”œâ”€â”€ dto/                 # DTOs (request/response)
â”‚       â”‚           â”œâ”€â”€ service/
â”‚       â”‚           â”‚   â”œâ”€â”€ data/            # Data loading
â”‚       â”‚           â”‚   â”œâ”€â”€ deepthinking/    # Deep thinking mode
â”‚       â”‚           â”‚   â”œâ”€â”€ embedding/       # Vietnamese embedding
â”‚       â”‚           â”‚   â”œâ”€â”€ llm/             # Ollama LLM
â”‚       â”‚           â”‚   â”œâ”€â”€ memory/          # Session management
â”‚       â”‚           â”‚   â”œâ”€â”€ monitoring/      # Performance tracking
â”‚       â”‚           â”‚   â””â”€â”€ rag/             # RAG core (search, rerank, fusion)
â”‚       â”‚           â””â”€â”€ util/                # Utilities (tokenizer, chunker...)
â”‚       â””â”€â”€ resources/
â”‚           â””â”€â”€ application.yml              # Spring Boot config
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ embedding_service.py                 # Python FastAPI embedding
â”‚   â””â”€â”€ faiss_service.py                     # FAISS search wrapper
â”œâ”€â”€ data/                                    # Datasets
â””â”€â”€ pom.xml                                  # Maven dependencies

```

## ğŸ“§ Contact

- **Email**: tominhducc@gmail.com
- **GitHub**: https://github.com/ghstmd/legal-rag-springboot

## ğŸ™ Acknowledgments

- [Spring AI](https://docs.spring.io/spring-ai/reference/) - AI framework
- [Ollama](https://ollama.com/) - LLM runtime
- [FAISS](https://github.com/facebookresearch/faiss) - Vector search
- [Sentence Transformers](https://www.sbert.net/) - Vietnamese embedding
