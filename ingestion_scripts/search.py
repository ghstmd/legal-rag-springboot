import json
import faiss
import numpy as np
from sentence_transformers import SentenceTransformer
from pyvi import ViTokenizer
import torch

class SearchEngine:
    def __init__(self, index_path="faiss.index", metadata_path="metadata.jsonl"):
        """
        Kh·ªüi t·∫°o search engine v·ªõi FAISS index v√† metadata
        """
        print("Loading search engine...")
        
        # Load FAISS index
        self.index = faiss.read_index(index_path)
        print(f"‚úÖ Loaded FAISS index with {self.index.ntotal} vectors")
        
        # Load metadata
        self.metadata = []
        with open(metadata_path, "r", encoding="utf-8") as f:
            for line in f:
                self.metadata.append(json.loads(line.strip()))
        print(f"‚úÖ Loaded {len(self.metadata)} metadata entries")
        
        # Initialize embedding model
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"üñ•Ô∏è  Using device: {self.device.upper()}")
        self.model = SentenceTransformer("dangvantuan/vietnamese-embedding", device=self.device)
        print("‚úÖ Model loaded")
    
    def tokenize_text(self, text):
        """Tokenize Vietnamese text"""
        return ViTokenizer.tokenize(text).split()
    
    def create_query_embedding(self, query):
        """
        T·∫°o embedding cho query (gi·ªëng c√°ch t·∫°o embedding cho documents)
        """
        tokens = self.tokenize_text(query)
        
        # Chia th√†nh subchunks nh∆∞ khi embedding
        subchunk_size = 60
        subchunks = [' '.join(tokens[j:j+subchunk_size]) for j in range(0, len(tokens), subchunk_size)]
        
        # Encode v√† l·∫•y mean
        sub_embeddings = self.model.encode(subchunks, convert_to_numpy=True)
        mean_embedding = np.mean(sub_embeddings, axis=0).astype('float32')
        
        return mean_embedding
    
    def search(self, query, top_k=5):
        """
        T√¨m ki·∫øm top_k documents g·∫ßn nh·∫•t v·ªõi query
        
        Args:
            query: C√¢u truy v·∫•n (string)
            top_k: S·ªë l∆∞·ª£ng k·∫øt qu·∫£ tr·∫£ v·ªÅ
            
        Returns:
            List of (metadata, distance) tuples
        """
        print(f"\nüîç Searching for: '{query}'")
        
        # T·∫°o embedding cho query
        query_embedding = self.create_query_embedding(query)
        query_vector = query_embedding.reshape(1, -1)
        
        # Search trong FAISS index
        distances, indices = self.index.search(query_vector, top_k)
        
        # L·∫•y metadata t∆∞∆°ng ·ª©ng
        results = []
        for i, (dist, idx) in enumerate(zip(distances[0], indices[0])):
            if idx < len(self.metadata):  # Ki·ªÉm tra index h·ª£p l·ªá
                results.append({
                    'rank': i + 1,
                    'distance': float(dist),
                    'metadata': self.metadata[idx]
                })
        
        return results
    
    def print_results(self, results):
        """In k·∫øt qu·∫£ search ra console"""
        print(f"\nüìä Found {len(results)} results:\n")
        print("="*80)
        
        for result in results:
            print(f"\nüèÜ Rank {result['rank']} | Distance: {result['distance']:.4f}")
            print("-"*80)
            
            metadata = result['metadata']
            
            # In c√°c tr∆∞·ªùng metadata
            for key, value in metadata.items():
                if key == 'chunk_content':
                    continue  # Skip content trong metadata n·∫øu c√≥
                print(f"  {key}: {value}")
            
            # In preview c·ªßa content n·∫øu c√≥
            if 'chunk_content' in metadata:
                content = metadata['chunk_content']
                preview = content[:200] + "..." if len(content) > 200 else content
                print(f"\n  üìÑ Preview:\n  {preview}")
            
            print("="*80)


def main():
    """
    Example usage
    """
    # Kh·ªüi t·∫°o search engine
    search_engine = SearchEngine(
        index_path="embed/normalized_faiss.index",
        metadata_path="embed/metadata.jsonl"
    )
    
    # Example queries
    queries = [
        "Mua ƒë·∫•t b·∫±ng gi·∫•y tay c√≥ ƒë∆∞·ª£c c·∫•p s·ªï ƒë·ªè kh√¥ng?",
        "ƒê·∫•t ch∆∞a c√≥ s·ªï ƒë·ªè c√≥ ƒë∆∞·ª£c x√¢y nh√† kh√¥ng?"
    ]

    for query in queries:
        results = search_engine.search(query, top_k=5)
        search_engine.print_results(results)
        print("\n" + "="*80 + "\n")


if __name__ == "__main__":
    main()